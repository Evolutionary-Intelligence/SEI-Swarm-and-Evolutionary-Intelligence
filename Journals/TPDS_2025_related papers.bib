
@article{jiang_real_2025,
	title = {Real {Relative} {Encoding} {Genetic} {Algorithm} for {Workflow} {Scheduling} in {Heterogeneous} {Distributed} {Computing} {Systems}},
	volume = {36},
	issn = {1558-2183},
	url = {https://ieeexplore.ieee.org/document/10745772},
	doi = {10.1109/TPDS.2024.3492210},
	abstract = {This paper introduces a novel Real Relative encoding Genetic Algorithm (R$^{\textrm{2}}$2GA) to tackle the workflow scheduling problem in heterogeneous distributed computing systems (HDCS). R$^{\textrm{2}}$2GA employs a unique encoding mechanism, using real numbers to represent the relative positions of tasks in the schedulable task set. Decoding is performed by interpreting these real numbers in relation to the directed acyclic graph (DAG) of the workflow. This approach ensures that any sequence of randomly generated real numbers, produced by cross-over and mutation operations, can always be decoded into a valid solution, as the precedence constraints between tasks are explicitly defined by the DAG. The proposed encoding and decoding mechanism simplifies genetic operations and facilitates efficient exploration of the solution space. This inherent flexibility also allows R$^{\textrm{2}}$2GA to be easily adapted to various optimization scenarios in workflow scheduling within HDCS. Additionally, R$^{\textrm{2}}$2GA overcomes several issues associated with traditional genetic algorithms (GAs) and existing real-number encoding GAs, such as the generation of chromosomes that violate task precedence constraints and the strict limitations on gene value ranges. Experimental results show that R$^{\textrm{2}}$2GA consistently delivers superior performance in terms of solution quality and efficiency compared to existing techniques.},
	number = {1},
	urldate = {2026-01-24},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Jiang, Junqiang and Sun, Zhifang and Lu, Ruiqi and Pan, Li and Peng, Zebo},
	month = jan,
	year = {2025},
	keywords = {Biological cells, Candidate task set, directed acyclic graph (DAG), Distributed computing, Encoding, genetic algorithm, Genetic algorithms, Genetic operators, Heuristic algorithms, Metaheuristics, Processor scheduling, Quality of service, real encoding, Scheduling, workflow scheduling},
	pages = {1--14},
	file = {Full Text PDF:D\:\\44444 Research\\zotero data\\storage\\2336LCKQ\\Jiang 等 - 2025 - Real Relative Encoding Genetic Algorithm for Workflow Scheduling in Heterogeneous Distributed Comput.pdf:application/pdf},
}

@article{zhou_umpipe_2025,
	title = {{UMPIPE}: {Unequal} {Microbatches}-{Based} {Pipeline} {Parallelism} for {Deep} {Neural} {Network} {Training}},
	volume = {36},
	issn = {1558-2183},
	shorttitle = {{UMPIPE}},
	url = {https://ieeexplore.ieee.org/document/10792656},
	doi = {10.1109/TPDS.2024.3515804},
	abstract = {The increasing need for large-scale deep neural networks (DNN) has made parallel training an area of intensive focus. One effective method, microbatch-based pipeline parallelism (notably GPipe), accelerates parallel training in various architectures. However, existing parallel training architectures normally use equal data partitioning (EDP), where each layer's process maintains identical microbatch-sizes. EDP may hinder training speed because different processes often require varying optimal microbatch-sizes. To address this, we introduce UMPIPE, a novel framework for unequal microbatches-based pipeline parallelism. UMPIPE enables unequal data partitions (UEDP) across processes to optimize resource utilization. We develop a recurrence formula to calculate the time cost in UMPIPE by considering both computation and communication processes. To further enhance UMPIPE's efficiency, we propose the Dual-Chromosome Genetic Algorithm for UMPIPE (DGAP) that accounts for the independent time costs of forward and backward propagation. Furthermore, we present TiDGAP, a two-level improvement on DGAP. TiDGAP accelerates the process by simultaneously calculating the end time for multiple individuals and microbatches using matrix operations. Our extensive experiments validate the dual-chromosome strategy's optimization benefits and TiDGAP's acceleration capabilities. TiDGAP can achieve better training schemes than baselines, such as the local greedy algorithm and the global greedy-based dynamic programming. Compared to (GPipe, PipeDream), UMPIPE achieves increases in training speed: (13.89,11.09)\%(13.89,11.09)\% for GPT1-14, (17.11, 7.96)\%(17.11,7.96)\% for VGG16 and {\textbackslash}geq (170,100)\%≥(170,100)\% for simulation networks.},
	number = {2},
	urldate = {2026-01-24},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Zhou, Guangyao and Tian, Wenhong and Buyya, Rajkumar and Wu, Kui},
	month = feb,
	year = {2025},
	keywords = {Computational modeling, Costs, Data models, data parallelism, genetic algorithm, Genetic algorithms, Parallel processing, Parallel training, pipeline parallelism, Pipeline processing, Pipelines, Tensors, Training, Transformers, unequal data partitions},
	pages = {293--307},
}

@article{li_non-intrusive_2025,
	title = {A {Non}-{Intrusive} {Multi}-objective {Task} {Scheduling} {Method} for {JointCloud} {Environment}},
	issn = {1558-2183},
	url = {https://ieeexplore.ieee.org/document/11113330},
	doi = {10.1109/TPDS.2025.3596012},
	abstract = {The advent of advanced technologies, such as large models, has precipitated a surging demand for computational resources, thereby driving the evolution of cloud computing services from single-cloud architectures to multi-cloud paradigms. The accompanying question is how to enable resources from different cloud service providers to collaborate efficiently. Although existing works have explored multi-cloud scheduling methods, most of these works are centralized scheduling, where the decision-maker can schedule computing resources across all clouds. However, this is nearly impossible given the current situation in which computing resources in different clouds come from various cloud service providers. In response to this challenge, JointCloud, a multi-cloud cooperation architecture, has been proposed, which aims at enhancing the cooperation among multiple clouds to provide efficient multi-cluster services. Following the idea of JointCloud, proposes a multi-objective evolutionary algorithm (MOEA) based method for task scheduling in multi-cluster cloud computing environments, without intervening in the intra-cluster scheduling scheme. In the proposed method, we construct a mathematical model with the optimization objectives of minimizing overall waiting time and load imbalance between clusters based on the actual operation data in China Computing NET (C $^{\textrm{2}}$ NET). In addition, we also develop an MOEA specifically tailored to address this problem. The performance of the proposed MOEA and existing state-of-the-art MOEAs is examined on the proposed problems. Comparison results highlight the promising performance of the proposed MOEA, the specifically tailored algorithm in effectively addressing the multi-cluster task scheduling problem. In addition, we also compared the results of the MOEAs with the results of three classical scheduling methods, the results proved the effectiveness of the MOEA-based method on this problem.},
	urldate = {2026-01-24},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Li, Lianghao and Mi, Haibo and Ding, Bo and Wang, Huaimin},
	year = {2025},
	keywords = {Approximation algorithms, Cloud computing, Cloud Computing, Computational modeling, Evolutionary Algorithm, Evolutionary computation, JointCloud, Large-scale Optimization, Linear programming, Minimax techniques, Multi-objective Optimization, Pareto optimization, Scheduling, Scheduling algorithms, Task Scheduling, Time factors},
	pages = {1--17},
	file = {Full Text PDF:D\:\\44444 Research\\zotero data\\storage\\RKVXMJ2Q\\Li 等 - 2025 - A Non-Intrusive Multi-objective Task Scheduling Method for JointCloud Environment.pdf:application/pdf},
}

@article{dong_slark_2025,
	title = {Slark: {A} {Performance} {Robust} {Decentralized} {Inter}-{Datacenter} {Deadline}-{Aware} {Coflows} {Scheduling} {Framework} {With} {Local} {Information}},
	volume = {36},
	issn = {1558-2183},
	shorttitle = {Slark},
	url = {https://ieeexplore.ieee.org/document/10770555},
	doi = {10.1109/TPDS.2024.3508275},
	abstract = {Inter-datacenter network applications generate massive coflows for purposes, e.g., backup, synchronization, and analytics, with deadline requirements. Decentralized coflow scheduling frameworks are desirable for their scalability in cross-domain deployment but grappling with the challenge of information agnosticism for lack of cross-domain privileges. Current information-agnostic coflow scheduling methods are incompatible with decentralized frameworks for relying on centralized controllers to continuously monitor and learn from coflow global transmission states to infer global coflow information. Alternative methods propose mechanisms for decentralized global coflow information gathering and synchronization. However, they require dedicated physical hardware or control logic, which could be impractical for incremental deployment. This article proposes Slark, a decentralized deadline-aware coflow scheduling framework, which meets coflows’ soft and hard deadline requirements using only local traffic information. It eschews requiring global coflow transmission states and dedicated hardware or control logic by leveraging multiple software-implemented scheduling agents working independently on each node and integrating such information agnosticism into node-specific bandwidth allocation by modeling it as a robust optimization problem with flow information on the other nodes represented as uncertain parameters. Subsequently, we validate the performance robustness of Slark by investigating how perturbations in the optimal objective function value and the associated optimal solution are affected by uncertain parameters. Finally, we propose a firebug-swarm-optimization-based heuristic algorithm to tackle the non-convexity in our problem. Experimental results demonstrate that Slark can significantly enhance transmission revenue and increase soft and hard deadline guarantee ratios by 10.52\% and 7.99\% on average.},
	number = {2},
	urldate = {2026-01-24},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Dong, Xiaodong and Nie, Lihai and Liu, Zheli and Xiang, Yang},
	month = feb,
	year = {2025},
	keywords = {Bandwidth, Channel allocation, Coflow scheduling, deadline guarantee, Hardware, inter-datacenter network, Logic, Monitoring, Optimization, Perturbation methods, Processor scheduling, robust optimization, Schedules, Synchronization},
	pages = {197--211},
	file = {Full Text PDF:D\:\\44444 Research\\zotero data\\storage\\7VU6X9DJ\\Dong 等 - 2025 - Slark A Performance Robust Decentralized Inter-Datacenter Deadline-Aware Coflows Scheduling Framewo.pdf:application/pdf},
}

@article{wei_energy_2025,
	title = {Energy {Efficient} and {Multi}-{Resource} {Optimization} for {Virtual} {Machine} {Placement} by {Improving} {MOEA}/{D}},
	volume = {36},
	issn = {1558-2183},
	url = {https://ieeexplore.ieee.org/document/10882864},
	doi = {10.1109/TPDS.2025.3538525},
	abstract = {The explosive growth of cloud services has led to the widespread construction of large-scale data centers to meet diverse and multifaceted cloud computing demands. However, this expansion has resulted in substantial energy consumption. Virtual machine placement (VMP) has been extensively studied as a means to provide flexible and scalable cloud services while optimizing energy efficiency. Yet, the increasing complexity and diversity of applications have posted VMP suffering from waste of resources and bottlenecks due to unbalanced utilization of multi-dimensional resources. To address these issues, this article proposes a bi-objective optimization model for VMP that jointly optimizes power consumption and multi-dimensional resource utilization. Solving this large-scale bi-objective model presents a significant challenge in balancing performance and computational complexity. To tackle this, an enhanced decomposition-based multi-objective evolutionary algorithm (MOEA/D) based on εɛ-domination, termed εɛ-IMOEA/D-M2M is designed to provide solutions for the proposed optimization. Compared with both heuristics and evolutionary algorithms, performance evaluations demonstrate that our proposed VMP algorithm effectively reduces power consumption and balances multidimensional resource utilization while significantly decreasing running time compared to both heuristic and traditional evolutionary algorithms.},
	number = {6},
	urldate = {2026-01-24},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Wei, Wenting and Gu, Huaxi and Xiao, Zhe and Chen, Yi},
	month = jun,
	year = {2025},
	keywords = {bi-objective optimization, Cloud computing, Computational modeling, Costs, Data centers, Energy consumption, energy efficiency, multi-resource balance, Optimization, Power demand, Resource management, Servers, Virtual machine placement, Virtual machines},
	pages = {1087--1099},
	file = {Full Text PDF:D\:\\44444 Research\\zotero data\\storage\\2UMM257U\\Wei 等 - 2025 - Energy Efficient and Multi-Resource Optimization for Virtual Machine Placement by Improving MOEAD.pdf:application/pdf},
}
